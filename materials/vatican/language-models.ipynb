{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90068ac2",
   "metadata": {},
   "source": [
    "# Language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c230123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea33d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vatican.vatican.database import VaticanMongoDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7209ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = VaticanMongoDb(db_name='vatican', collection='tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c2d3c0",
   "metadata": {},
   "source": [
    "## General idea\n",
    "\n",
    "A language model is a way to estimate\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, \\dots, w_{n-1}, w_{n})\n",
    "$$\n",
    "\n",
    "The Naive way of doing this is\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, \\dots, w_{n-1}, w_{n}) = P(w_1) \\times P(w_2) \\times P(w_3) \\times \\dots \\times P(w_{n-1}) \\times P(w_n)\n",
    "$$\n",
    "\n",
    "As an alternative, \n",
    "this can be seen as the problem of estimating the next word in the sequence and than take the product of all the estimations\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, \\dots, w_{n-1}, w_{n}) = P(w_2 \\mid w_1) \\times P(w_3 \\mid w_1, w_2) \\times P(w_4 \\mid w_1, w_2, w_3) \\times \\dots \\times P(w_n \\mid w_1, \\dots w_{n-1})\n",
    "$$\n",
    "\n",
    "**Question: what is the main difference with**\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, \\dots, w_{n-1}, w_{n}) = P(w_1) \\times P(w_2) \\times P(w_3) \\times \\dots \\times P(w_{n-1}) \\times P(w_n)\n",
    "$$\n",
    "\n",
    "\n",
    "Now, in general, if we want to estimate $P(A \\mid B)$ we can compute\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{count(A, B)}{\\sum\\limits_{A_i}count(A_i, B)}\n",
    "$$\n",
    "\n",
    "When we observe $A$ and $B$ in a sequence, this is just\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{count(A, B)}{count(B)}\n",
    "$$\n",
    "\n",
    "to apply the idea to the text, we need to keep an index that says how many times a word $A$ follows a word $B$ for any word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdc6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545955d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a6ed685e344c26a2da2801b2471486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_pairs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for pope, document in tqdm(db.documents):\n",
    "    if pope == 'Paul VI':\n",
    "        for sentence in db.get_sentences(pope, document, field='text'):\n",
    "            tokens = ['#START'] + [x['token'].lower() for x in sentence] + ['#END']\n",
    "            for a, b in nltk.ngrams(tokens, n=2):\n",
    "                index_pairs[a][b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc71d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(cristiano | matrimonio) = count(matrimonio, cristiano) / count(matrimonio)\n",
      "0.07575757575757576\n"
     ]
    }
   ],
   "source": [
    "print(\"P(cristiano | matrimonio) = count(matrimonio, cristiano) / count(matrimonio)\")\n",
    "print(index_pairs['matrimonio']['cristiano'] / sum(index_pairs['matrimonio'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6445c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",            0.293939\n",
       ".            0.078788\n",
       "cristiano    0.075758\n",
       "e            0.072727\n",
       ";            0.027273\n",
       "è            0.027273\n",
       ":            0.021212\n",
       "dei          0.018182\n",
       "si           0.018182\n",
       "non          0.018182\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_prob = {}\n",
    "freq_matrimonio = sum(index_pairs['matrimonio'].values())\n",
    "for word, freq in index_pairs['matrimonio'].items():\n",
    "    ngram_prob[word] = freq / freq_matrimonio\n",
    "pd.Series(ngram_prob).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce0575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cristiano    175\n",
       "(             28\n",
       "si            42\n",
       ";             63\n",
       ",            679\n",
       "non           42\n",
       "senza          7\n",
       "di            14\n",
       "e            168\n",
       "è             63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index_pairs['matrimonio']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e71db6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = ['#START']\n",
    "for i in range(10):\n",
    "    prec = sequence[-1]\n",
    "    candidates = index_pairs['#START']\n",
    "    words = [x for x, y in candidates.items()]\n",
    "    probs = [y for x, y in candidates.items()]\n",
    "    new_word = np.random.choice(words, \n",
    "                     p=[x / sum(probs) for x in probs])\n",
    "    sequence.append(new_word)\n",
    "    if new_word == '#END':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c43abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#START', '[', 'enc', '2.7', 'questa', '(', '472', 'enc', '[', ',', ',']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f17df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crike",
   "language": "python",
   "name": "crike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
