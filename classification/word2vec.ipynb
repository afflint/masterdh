{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Gensim implementation\n",
    "> Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., & Joulin, A. (2017). Advances in pre-training distributed word representations. arXiv preprint arXiv:1712.09405."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format(datapath(\"/Users/flint/Data/word2vec/GoogleNews-vectors-negative300.bin\"), \n",
    "                                       binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = wv.get_vector('peach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peaches', 0.7132657766342163),\n",
       " ('strawberry', 0.6729940176010132),\n",
       " ('apricot', 0.6522811651229858),\n",
       " ('melon', 0.6460169553756714),\n",
       " ('plums', 0.6374126076698303),\n",
       " ('pear', 0.6346296072006226),\n",
       " ('berry', 0.6229482889175415),\n",
       " ('mandarin_orange', 0.617423951625824),\n",
       " ('nectarine', 0.6131626963615417),\n",
       " ('strawberries', 0.6110720634460449)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('peach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle 0.7821096181869507\n",
      "cars 0.7423831224441528\n",
      "SUV 0.7160962224006653\n",
      "minivan 0.6907036900520325\n",
      "truck 0.6735789775848389\n",
      "Car 0.6677608489990234\n",
      "Ford_Focus 0.667320191860199\n",
      "Honda_Civic 0.6626849174499512\n",
      "Jeep 0.651133120059967\n",
      "pickup_truck 0.6441438794136047\n"
     ]
    }
   ],
   "source": [
    "for x, y in wv.most_similar('car'):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for word in ['peach', 'apricot', 'strawberry', 'fish', 'meat', 'vegetables', 'milk']:\n",
    "    vectors.append(wv.get_vector(word))\n",
    "V = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = V.mean(axis=0)\n",
    "#v = v - wv.get_vector('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strawberry', 0.7836589813232422),\n",
       " ('vegetables', 0.7646373510360718),\n",
       " ('strawberries', 0.7575767040252686),\n",
       " ('peaches', 0.754625141620636),\n",
       " ('berries', 0.741344153881073),\n",
       " ('tomato', 0.7389938831329346),\n",
       " ('apricots', 0.7348976135253906),\n",
       " ('tomatoes', 0.7201975584030151),\n",
       " ('cherries', 0.719590961933136),\n",
       " ('asparagus', 0.7166165709495544),\n",
       " ('fruit', 0.7139172554016113),\n",
       " ('peach', 0.7131540179252625),\n",
       " ('pears', 0.7125092148780823),\n",
       " ('Bing_cherries', 0.7114951014518738),\n",
       " ('sweet_potatoes', 0.7094361782073975),\n",
       " ('vegetable', 0.7081252932548523),\n",
       " ('apricot', 0.7071393132209778),\n",
       " ('blueberries', 0.7059823870658875),\n",
       " ('blueberry', 0.703717052936554),\n",
       " ('fresh_figs', 0.7034894227981567)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(v, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy\n",
    "\n",
    "FRANCE : PARIS = ITALY : ?\n",
    "\n",
    "PARIS - FRANCE + ITALY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Queen', 0.5515626668930054),\n",
       " ('Oprah_BFF_Gayle', 0.47597548365592957),\n",
       " ('Geoffrey_Rush_Exit', 0.46460166573524475),\n",
       " ('Princess', 0.4533674716949463),\n",
       " ('Yvonne_Stickney', 0.4507041573524475),\n",
       " ('L._Bonauto', 0.4422135353088379),\n",
       " ('gal_pal_Gayle', 0.4408389925956726),\n",
       " ('Alveda_C.', 0.4402790665626526),\n",
       " ('Tupou_V.', 0.4373864233493805),\n",
       " ('K._Letourneau', 0.4351031482219696)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['King', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"school professor car student\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = wv['school']\n",
    "vr = wv['professor']\n",
    "vx = wv['student']\n",
    "m = (vp + vr + vx) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 0.8481254577636719),\n",
       " ('professor', 0.7627506852149963),\n",
       " ('teacher', 0.6942789554595947),\n",
       " ('school', 0.6849855780601501),\n",
       " ('students', 0.6768636703491211),\n",
       " ('lecturer', 0.6700003147125244),\n",
       " ('faculty', 0.645453155040741),\n",
       " ('university', 0.6376535892486572),\n",
       " ('professors', 0.6346085667610168),\n",
       " ('associate_professor', 0.6325882077217102)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lecturer'\t'school'\t0.18\n",
      "'lecturer'\t'professor'\t0.80\n",
      "'lecturer'\t'student'\t0.43\n",
      "'lecturer'\t'teacher'\t0.48\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('lecturer', 'school'),\n",
    "    ('lecturer', 'professor'),\n",
    "    ('lecturer', 'student'),\n",
    "    ('lecturer', 'teacher'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sell', 0.8308461308479309),\n",
       " ('purchase', 0.7639904618263245),\n",
       " ('buying', 0.7209187746047974),\n",
       " ('bought', 0.7087081074714661),\n",
       " ('buys', 0.6617438197135925),\n",
       " ('Buy', 0.5850198864936829),\n",
       " ('tobuy', 0.5843992829322815),\n",
       " ('purchased', 0.582695484161377),\n",
       " ('Buying', 0.578020453453064),\n",
       " ('acquire', 0.5730165839195251)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31760776"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity('buy', 'money')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = _ # assume there's one document per line, tokens separated by whitespace\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: train a model from your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()['wikibio']['rawdata']\n",
    "data = list(db.find({\n",
    "    'subdata': 'train', 'box.occupation': {'$exists': True}\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in data:\n",
    "    for s in doc['sentences']:\n",
    "        sentences.append(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647383"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sentences, vector_size=300, window=6, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dance', 0.5563018918037415),\n",
       " ('tunes', 0.5537866950035095),\n",
       " ('hip-hop', 0.5531975030899048),\n",
       " ('rhythms', 0.5528717637062073),\n",
       " ('electronica', 0.5446825623512268),\n",
       " ('techno', 0.5336247086524963),\n",
       " ('sounds', 0.5252417922019958),\n",
       " ('orchestral', 0.5198730826377869),\n",
       " ('jazz', 0.5157392024993896),\n",
       " ('beats', 0.5152225494384766)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('music')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(keys.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocabulary[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = []\n",
    "for w in voc:\n",
    "    M.append(model.wv.get_vector(w))\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=100)\n",
    "y_pred = kmeans.fit_predict(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for i, y in enumerate(y_pred):\n",
    "    clusters[y].append(voc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'family',\n",
       " 'children',\n",
       " 'married',\n",
       " 'son',\n",
       " 'father',\n",
       " 'wife',\n",
       " 'brother',\n",
       " 'daughter',\n",
       " 'mother',\n",
       " 'child',\n",
       " 'brothers',\n",
       " 'husband',\n",
       " 'sister',\n",
       " 'whom',\n",
       " 'partner',\n",
       " 'friend',\n",
       " 'parents',\n",
       " 'friends',\n",
       " 'younger',\n",
       " 'sons',\n",
       " 'marriage',\n",
       " 'daughters',\n",
       " 'relationship',\n",
       " 'older',\n",
       " 'uncle',\n",
       " 'nickname',\n",
       " 'cousin',\n",
       " 'sisters',\n",
       " 'grandfather',\n",
       " 'grandson',\n",
       " 'nephew',\n",
       " 'widow',\n",
       " 'siblings',\n",
       " 'grandmother']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
